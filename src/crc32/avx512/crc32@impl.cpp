/* Generated by https://github.com/corsix/fast-crc32/ using: */
/* C:\Users\alekesej\Documents\Programming\Tests\fast-crc32\generate.exe -i avx512 -p crc32c -a v12x2s16x5k64e */
/* MIT licensed */

#include <immintrin.h>
#include <nmmintrin.h>
#include <stddef.h>
#include <stdint.h>

#if defined(_MSC_VER)
    #define CRC_AINLINE  static __forceinline
    #define CRC_ALIGN(n) __declspec(align(n))
#else
    #define CRC_AINLINE  static __inline __attribute__((always_inline))
    #define CRC_ALIGN(n) __attribute__((aligned(n)))
#endif
#define CRC_EXPORT extern

#define clmul_lo(a, b) (_mm_clmulepi64_si128((a), (b), 0))
#define clmul_hi(a, b) (_mm_clmulepi64_si128((a), (b), 17))

CRC_AINLINE __m128i clmul_scalar(uint32_t a, uint32_t b)
{
    return _mm_clmulepi64_si128(_mm_cvtsi32_si128(a), _mm_cvtsi32_si128(b), 0);
}

static uint32_t xnmodp(uint64_t n) /* x^n mod P, in log(n) time */
{
    uint64_t stack = ~(uint64_t)1;
    uint32_t acc, low;
    for (; n > 191; n = (n >> 1) - 16)
    {
        stack = (stack << 1) + (n & 1);
    }
    stack = ~stack;
    acc = ((uint32_t)0x80000000) >> (n & 31);
    for (n >>= 5; n; --n)
    {
        acc = _mm_crc32_u32(acc, 0);
    }
    while ((low = stack & 1), stack >>= 1)
    {
        __m128i x = _mm_cvtsi32_si128(acc);
        uint64_t y = _mm_cvtsi128_si64(_mm_clmulepi64_si128(x, x, 0));
        acc = _mm_crc32_u64(0, y << low);
    }
    return acc;
}

CRC_AINLINE __m128i crc_shift(uint32_t crc, size_t nbytes) { return clmul_scalar(crc, xnmodp(nbytes * 8 - 33)); }

extern "C"
{
    __declspec(dllexport) uint32_t crc32_impl(uint32_t crc0, const char *buf, size_t len)
    {
        crc0 = ~crc0;
        for (; len && ((uintptr_t)buf & 7); --len)
        {
            crc0 = _mm_crc32_u8(crc0, *buf++);
        }
        if (((uintptr_t)buf & 8) && len >= 8)
        {
            crc0 = _mm_crc32_u64(crc0, *(const uint64_t *)buf);
            buf += 8;
            len -= 8;
        }
        if (len >= 1024)
        {
            const char *end = buf + len;
            size_t blk = (len - 0) / 1024;
            size_t klen = blk * 40;
            const char *buf2 = buf + klen * 16;
            const char *limit = buf + klen - 80;
            uint32_t crc1 = 0;
            uint32_t crc2 = 0;
            uint32_t crc3 = 0;
            uint32_t crc4 = 0;
            uint32_t crc5 = 0;
            uint32_t crc6 = 0;
            uint32_t crc7 = 0;
            uint32_t crc8 = 0;
            uint32_t crc9 = 0;
            uint32_t crc10 = 0;
            uint32_t crc11 = 0;
            uint32_t crc12 = 0;
            uint32_t crc13 = 0;
            uint32_t crc14 = 0;
            uint32_t crc15 = 0;
            __m128i vc0;
            __m128i vc1;
            __m128i vc2;
            __m128i vc3;
            __m128i vc4;
            __m128i vc5;
            __m128i vc6;
            __m128i vc7;
            __m128i vc8;
            __m128i vc9;
            __m128i vc10;
            __m128i vc11;
            __m128i vc12;
            __m128i vc13;
            __m128i vc14;
            __m128i vc15;
            uint64_t vc;
            /* First vector chunk. */
            __m128i x0 = _mm_loadu_si128((const __m128i *)buf2), y0;
            __m128i x1 = _mm_loadu_si128((const __m128i *)(buf2 + 16)), y1;
            __m128i x2 = _mm_loadu_si128((const __m128i *)(buf2 + 32)), y2;
            __m128i x3 = _mm_loadu_si128((const __m128i *)(buf2 + 48)), y3;
            __m128i x4 = _mm_loadu_si128((const __m128i *)(buf2 + 64)), y4;
            __m128i x5 = _mm_loadu_si128((const __m128i *)(buf2 + 80)), y5;
            __m128i x6 = _mm_loadu_si128((const __m128i *)(buf2 + 96)), y6;
            __m128i x7 = _mm_loadu_si128((const __m128i *)(buf2 + 112)), y7;
            __m128i x8 = _mm_loadu_si128((const __m128i *)(buf2 + 128)), y8;
            __m128i x9 = _mm_loadu_si128((const __m128i *)(buf2 + 144)), y9;
            __m128i x10 = _mm_loadu_si128((const __m128i *)(buf2 + 160)), y10;
            __m128i x11 = _mm_loadu_si128((const __m128i *)(buf2 + 176)), y11;
            __m128i k;
            k = _mm_setr_epi32(0xa87ab8a8, 0, 0xab7aff2a, 0);
            y0 = clmul_lo(x0, k), x0 = clmul_hi(x0, k);
            y1 = clmul_lo(x1, k), x1 = clmul_hi(x1, k);
            y2 = clmul_lo(x2, k), x2 = clmul_hi(x2, k);
            y3 = clmul_lo(x3, k), x3 = clmul_hi(x3, k);
            y4 = clmul_lo(x4, k), x4 = clmul_hi(x4, k);
            y5 = clmul_lo(x5, k), x5 = clmul_hi(x5, k);
            y6 = clmul_lo(x6, k), x6 = clmul_hi(x6, k);
            y7 = clmul_lo(x7, k), x7 = clmul_hi(x7, k);
            y8 = clmul_lo(x8, k), x8 = clmul_hi(x8, k);
            y9 = clmul_lo(x9, k), x9 = clmul_hi(x9, k);
            y10 = clmul_lo(x10, k), x10 = clmul_hi(x10, k);
            y11 = clmul_lo(x11, k), x11 = clmul_hi(x11, k);
            x0 = _mm_ternarylogic_epi64(x0, y0, _mm_loadu_si128((const __m128i *)(buf2 + 192)), 0x96);
            x1 = _mm_ternarylogic_epi64(x1, y1, _mm_loadu_si128((const __m128i *)(buf2 + 208)), 0x96);
            x2 = _mm_ternarylogic_epi64(x2, y2, _mm_loadu_si128((const __m128i *)(buf2 + 224)), 0x96);
            x3 = _mm_ternarylogic_epi64(x3, y3, _mm_loadu_si128((const __m128i *)(buf2 + 240)), 0x96);
            x4 = _mm_ternarylogic_epi64(x4, y4, _mm_loadu_si128((const __m128i *)(buf2 + 256)), 0x96);
            x5 = _mm_ternarylogic_epi64(x5, y5, _mm_loadu_si128((const __m128i *)(buf2 + 272)), 0x96);
            x6 = _mm_ternarylogic_epi64(x6, y6, _mm_loadu_si128((const __m128i *)(buf2 + 288)), 0x96);
            x7 = _mm_ternarylogic_epi64(x7, y7, _mm_loadu_si128((const __m128i *)(buf2 + 304)), 0x96);
            x8 = _mm_ternarylogic_epi64(x8, y8, _mm_loadu_si128((const __m128i *)(buf2 + 320)), 0x96);
            x9 = _mm_ternarylogic_epi64(x9, y9, _mm_loadu_si128((const __m128i *)(buf2 + 336)), 0x96);
            x10 = _mm_ternarylogic_epi64(x10, y10, _mm_loadu_si128((const __m128i *)(buf2 + 352)), 0x96);
            x11 = _mm_ternarylogic_epi64(x11, y11, _mm_loadu_si128((const __m128i *)(buf2 + 368)), 0x96);
            buf2 += 384;
            /* Main loop. */
            while (buf <= limit)
            {
                y0 = clmul_lo(x0, k), x0 = clmul_hi(x0, k);
                y1 = clmul_lo(x1, k), x1 = clmul_hi(x1, k);
                y2 = clmul_lo(x2, k), x2 = clmul_hi(x2, k);
                y3 = clmul_lo(x3, k), x3 = clmul_hi(x3, k);
                y4 = clmul_lo(x4, k), x4 = clmul_hi(x4, k);
                y5 = clmul_lo(x5, k), x5 = clmul_hi(x5, k);
                y6 = clmul_lo(x6, k), x6 = clmul_hi(x6, k);
                y7 = clmul_lo(x7, k), x7 = clmul_hi(x7, k);
                y8 = clmul_lo(x8, k), x8 = clmul_hi(x8, k);
                y9 = clmul_lo(x9, k), x9 = clmul_hi(x9, k);
                y10 = clmul_lo(x10, k), x10 = clmul_hi(x10, k);
                y11 = clmul_lo(x11, k), x11 = clmul_hi(x11, k);
                x0 = _mm_ternarylogic_epi64(x0, y0, _mm_loadu_si128((const __m128i *)buf2), 0x96);
                x1 = _mm_ternarylogic_epi64(x1, y1, _mm_loadu_si128((const __m128i *)(buf2 + 16)), 0x96);
                x2 = _mm_ternarylogic_epi64(x2, y2, _mm_loadu_si128((const __m128i *)(buf2 + 32)), 0x96);
                x3 = _mm_ternarylogic_epi64(x3, y3, _mm_loadu_si128((const __m128i *)(buf2 + 48)), 0x96);
                x4 = _mm_ternarylogic_epi64(x4, y4, _mm_loadu_si128((const __m128i *)(buf2 + 64)), 0x96);
                x5 = _mm_ternarylogic_epi64(x5, y5, _mm_loadu_si128((const __m128i *)(buf2 + 80)), 0x96);
                x6 = _mm_ternarylogic_epi64(x6, y6, _mm_loadu_si128((const __m128i *)(buf2 + 96)), 0x96);
                x7 = _mm_ternarylogic_epi64(x7, y7, _mm_loadu_si128((const __m128i *)(buf2 + 112)), 0x96);
                x8 = _mm_ternarylogic_epi64(x8, y8, _mm_loadu_si128((const __m128i *)(buf2 + 128)), 0x96);
                x9 = _mm_ternarylogic_epi64(x9, y9, _mm_loadu_si128((const __m128i *)(buf2 + 144)), 0x96);
                x10 = _mm_ternarylogic_epi64(x10, y10, _mm_loadu_si128((const __m128i *)(buf2 + 160)), 0x96);
                x11 = _mm_ternarylogic_epi64(x11, y11, _mm_loadu_si128((const __m128i *)(buf2 + 176)), 0x96);
                y0 = clmul_lo(x0, k), x0 = clmul_hi(x0, k);
                y1 = clmul_lo(x1, k), x1 = clmul_hi(x1, k);
                y2 = clmul_lo(x2, k), x2 = clmul_hi(x2, k);
                y3 = clmul_lo(x3, k), x3 = clmul_hi(x3, k);
                y4 = clmul_lo(x4, k), x4 = clmul_hi(x4, k);
                y5 = clmul_lo(x5, k), x5 = clmul_hi(x5, k);
                y6 = clmul_lo(x6, k), x6 = clmul_hi(x6, k);
                y7 = clmul_lo(x7, k), x7 = clmul_hi(x7, k);
                y8 = clmul_lo(x8, k), x8 = clmul_hi(x8, k);
                y9 = clmul_lo(x9, k), x9 = clmul_hi(x9, k);
                y10 = clmul_lo(x10, k), x10 = clmul_hi(x10, k);
                y11 = clmul_lo(x11, k), x11 = clmul_hi(x11, k);
                x0 = _mm_ternarylogic_epi64(x0, y0, _mm_loadu_si128((const __m128i *)(buf2 + 192)), 0x96);
                x1 = _mm_ternarylogic_epi64(x1, y1, _mm_loadu_si128((const __m128i *)(buf2 + 208)), 0x96);
                x2 = _mm_ternarylogic_epi64(x2, y2, _mm_loadu_si128((const __m128i *)(buf2 + 224)), 0x96);
                x3 = _mm_ternarylogic_epi64(x3, y3, _mm_loadu_si128((const __m128i *)(buf2 + 240)), 0x96);
                x4 = _mm_ternarylogic_epi64(x4, y4, _mm_loadu_si128((const __m128i *)(buf2 + 256)), 0x96);
                x5 = _mm_ternarylogic_epi64(x5, y5, _mm_loadu_si128((const __m128i *)(buf2 + 272)), 0x96);
                x6 = _mm_ternarylogic_epi64(x6, y6, _mm_loadu_si128((const __m128i *)(buf2 + 288)), 0x96);
                x7 = _mm_ternarylogic_epi64(x7, y7, _mm_loadu_si128((const __m128i *)(buf2 + 304)), 0x96);
                x8 = _mm_ternarylogic_epi64(x8, y8, _mm_loadu_si128((const __m128i *)(buf2 + 320)), 0x96);
                x9 = _mm_ternarylogic_epi64(x9, y9, _mm_loadu_si128((const __m128i *)(buf2 + 336)), 0x96);
                x10 = _mm_ternarylogic_epi64(x10, y10, _mm_loadu_si128((const __m128i *)(buf2 + 352)), 0x96);
                x11 = _mm_ternarylogic_epi64(x11, y11, _mm_loadu_si128((const __m128i *)(buf2 + 368)), 0x96);
                crc0 = _mm_crc32_u64(crc0, *(const uint64_t *)buf);
                crc1 = _mm_crc32_u64(crc1, *(const uint64_t *)(buf + klen));
                crc2 = _mm_crc32_u64(crc2, *(const uint64_t *)(buf + klen * 2));
                crc3 = _mm_crc32_u64(crc3, *(const uint64_t *)(buf + klen * 3));
                crc4 = _mm_crc32_u64(crc4, *(const uint64_t *)(buf + klen * 4));
                crc5 = _mm_crc32_u64(crc5, *(const uint64_t *)(buf + klen * 5));
                crc6 = _mm_crc32_u64(crc6, *(const uint64_t *)(buf + klen * 6));
                crc7 = _mm_crc32_u64(crc7, *(const uint64_t *)(buf + klen * 7));
                crc8 = _mm_crc32_u64(crc8, *(const uint64_t *)(buf + klen * 8));
                crc9 = _mm_crc32_u64(crc9, *(const uint64_t *)(buf + klen * 9));
                crc10 = _mm_crc32_u64(crc10, *(const uint64_t *)(buf + klen * 10));
                crc11 = _mm_crc32_u64(crc11, *(const uint64_t *)(buf + klen * 11));
                crc12 = _mm_crc32_u64(crc12, *(const uint64_t *)(buf + klen * 12));
                crc13 = _mm_crc32_u64(crc13, *(const uint64_t *)(buf + klen * 13));
                crc14 = _mm_crc32_u64(crc14, *(const uint64_t *)(buf + klen * 14));
                crc15 = _mm_crc32_u64(crc15, *(const uint64_t *)(buf + klen * 15));
                crc0 = _mm_crc32_u64(crc0, *(const uint64_t *)(buf + 8));
                crc1 = _mm_crc32_u64(crc1, *(const uint64_t *)(buf + klen + 8));
                crc2 = _mm_crc32_u64(crc2, *(const uint64_t *)(buf + klen * 2 + 8));
                crc3 = _mm_crc32_u64(crc3, *(const uint64_t *)(buf + klen * 3 + 8));
                crc4 = _mm_crc32_u64(crc4, *(const uint64_t *)(buf + klen * 4 + 8));
                crc5 = _mm_crc32_u64(crc5, *(const uint64_t *)(buf + klen * 5 + 8));
                crc6 = _mm_crc32_u64(crc6, *(const uint64_t *)(buf + klen * 6 + 8));
                crc7 = _mm_crc32_u64(crc7, *(const uint64_t *)(buf + klen * 7 + 8));
                crc8 = _mm_crc32_u64(crc8, *(const uint64_t *)(buf + klen * 8 + 8));
                crc9 = _mm_crc32_u64(crc9, *(const uint64_t *)(buf + klen * 9 + 8));
                crc10 = _mm_crc32_u64(crc10, *(const uint64_t *)(buf + klen * 10 + 8));
                crc11 = _mm_crc32_u64(crc11, *(const uint64_t *)(buf + klen * 11 + 8));
                crc12 = _mm_crc32_u64(crc12, *(const uint64_t *)(buf + klen * 12 + 8));
                crc13 = _mm_crc32_u64(crc13, *(const uint64_t *)(buf + klen * 13 + 8));
                crc14 = _mm_crc32_u64(crc14, *(const uint64_t *)(buf + klen * 14 + 8));
                crc15 = _mm_crc32_u64(crc15, *(const uint64_t *)(buf + klen * 15 + 8));
                crc0 = _mm_crc32_u64(crc0, *(const uint64_t *)(buf + 16));
                crc1 = _mm_crc32_u64(crc1, *(const uint64_t *)(buf + klen + 16));
                crc2 = _mm_crc32_u64(crc2, *(const uint64_t *)(buf + klen * 2 + 16));
                crc3 = _mm_crc32_u64(crc3, *(const uint64_t *)(buf + klen * 3 + 16));
                crc4 = _mm_crc32_u64(crc4, *(const uint64_t *)(buf + klen * 4 + 16));
                crc5 = _mm_crc32_u64(crc5, *(const uint64_t *)(buf + klen * 5 + 16));
                crc6 = _mm_crc32_u64(crc6, *(const uint64_t *)(buf + klen * 6 + 16));
                crc7 = _mm_crc32_u64(crc7, *(const uint64_t *)(buf + klen * 7 + 16));
                crc8 = _mm_crc32_u64(crc8, *(const uint64_t *)(buf + klen * 8 + 16));
                crc9 = _mm_crc32_u64(crc9, *(const uint64_t *)(buf + klen * 9 + 16));
                crc10 = _mm_crc32_u64(crc10, *(const uint64_t *)(buf + klen * 10 + 16));
                crc11 = _mm_crc32_u64(crc11, *(const uint64_t *)(buf + klen * 11 + 16));
                crc12 = _mm_crc32_u64(crc12, *(const uint64_t *)(buf + klen * 12 + 16));
                crc13 = _mm_crc32_u64(crc13, *(const uint64_t *)(buf + klen * 13 + 16));
                crc14 = _mm_crc32_u64(crc14, *(const uint64_t *)(buf + klen * 14 + 16));
                crc15 = _mm_crc32_u64(crc15, *(const uint64_t *)(buf + klen * 15 + 16));
                crc0 = _mm_crc32_u64(crc0, *(const uint64_t *)(buf + 24));
                crc1 = _mm_crc32_u64(crc1, *(const uint64_t *)(buf + klen + 24));
                crc2 = _mm_crc32_u64(crc2, *(const uint64_t *)(buf + klen * 2 + 24));
                crc3 = _mm_crc32_u64(crc3, *(const uint64_t *)(buf + klen * 3 + 24));
                crc4 = _mm_crc32_u64(crc4, *(const uint64_t *)(buf + klen * 4 + 24));
                crc5 = _mm_crc32_u64(crc5, *(const uint64_t *)(buf + klen * 5 + 24));
                crc6 = _mm_crc32_u64(crc6, *(const uint64_t *)(buf + klen * 6 + 24));
                crc7 = _mm_crc32_u64(crc7, *(const uint64_t *)(buf + klen * 7 + 24));
                crc8 = _mm_crc32_u64(crc8, *(const uint64_t *)(buf + klen * 8 + 24));
                crc9 = _mm_crc32_u64(crc9, *(const uint64_t *)(buf + klen * 9 + 24));
                crc10 = _mm_crc32_u64(crc10, *(const uint64_t *)(buf + klen * 10 + 24));
                crc11 = _mm_crc32_u64(crc11, *(const uint64_t *)(buf + klen * 11 + 24));
                crc12 = _mm_crc32_u64(crc12, *(const uint64_t *)(buf + klen * 12 + 24));
                crc13 = _mm_crc32_u64(crc13, *(const uint64_t *)(buf + klen * 13 + 24));
                crc14 = _mm_crc32_u64(crc14, *(const uint64_t *)(buf + klen * 14 + 24));
                crc15 = _mm_crc32_u64(crc15, *(const uint64_t *)(buf + klen * 15 + 24));
                crc0 = _mm_crc32_u64(crc0, *(const uint64_t *)(buf + 32));
                crc1 = _mm_crc32_u64(crc1, *(const uint64_t *)(buf + klen + 32));
                crc2 = _mm_crc32_u64(crc2, *(const uint64_t *)(buf + klen * 2 + 32));
                crc3 = _mm_crc32_u64(crc3, *(const uint64_t *)(buf + klen * 3 + 32));
                crc4 = _mm_crc32_u64(crc4, *(const uint64_t *)(buf + klen * 4 + 32));
                crc5 = _mm_crc32_u64(crc5, *(const uint64_t *)(buf + klen * 5 + 32));
                crc6 = _mm_crc32_u64(crc6, *(const uint64_t *)(buf + klen * 6 + 32));
                crc7 = _mm_crc32_u64(crc7, *(const uint64_t *)(buf + klen * 7 + 32));
                crc8 = _mm_crc32_u64(crc8, *(const uint64_t *)(buf + klen * 8 + 32));
                crc9 = _mm_crc32_u64(crc9, *(const uint64_t *)(buf + klen * 9 + 32));
                crc10 = _mm_crc32_u64(crc10, *(const uint64_t *)(buf + klen * 10 + 32));
                crc11 = _mm_crc32_u64(crc11, *(const uint64_t *)(buf + klen * 11 + 32));
                crc12 = _mm_crc32_u64(crc12, *(const uint64_t *)(buf + klen * 12 + 32));
                crc13 = _mm_crc32_u64(crc13, *(const uint64_t *)(buf + klen * 13 + 32));
                crc14 = _mm_crc32_u64(crc14, *(const uint64_t *)(buf + klen * 14 + 32));
                crc15 = _mm_crc32_u64(crc15, *(const uint64_t *)(buf + klen * 15 + 32));
                buf += 40;
                buf2 += 384;
            }
            /* Reduce x0 ... x11 to just x0. */
            k = _mm_setr_epi32(0xf20c0dfe, 0, 0x493c7d27, 0);
            y0 = clmul_lo(x0, k), x0 = clmul_hi(x0, k);
            y2 = clmul_lo(x2, k), x2 = clmul_hi(x2, k);
            y4 = clmul_lo(x4, k), x4 = clmul_hi(x4, k);
            y6 = clmul_lo(x6, k), x6 = clmul_hi(x6, k);
            y8 = clmul_lo(x8, k), x8 = clmul_hi(x8, k);
            y10 = clmul_lo(x10, k), x10 = clmul_hi(x10, k);
            x0 = _mm_ternarylogic_epi64(x0, y0, x1, 0x96);
            x2 = _mm_ternarylogic_epi64(x2, y2, x3, 0x96);
            x4 = _mm_ternarylogic_epi64(x4, y4, x5, 0x96);
            x6 = _mm_ternarylogic_epi64(x6, y6, x7, 0x96);
            x8 = _mm_ternarylogic_epi64(x8, y8, x9, 0x96);
            x10 = _mm_ternarylogic_epi64(x10, y10, x11, 0x96);
            k = _mm_setr_epi32(0x3da6d0cb, 0, 0xba4fc28e, 0);
            y0 = clmul_lo(x0, k), x0 = clmul_hi(x0, k);
            y4 = clmul_lo(x4, k), x4 = clmul_hi(x4, k);
            y8 = clmul_lo(x8, k), x8 = clmul_hi(x8, k);
            x0 = _mm_ternarylogic_epi64(x0, y0, x2, 0x96);
            x4 = _mm_ternarylogic_epi64(x4, y4, x6, 0x96);
            x8 = _mm_ternarylogic_epi64(x8, y8, x10, 0x96);
            k = _mm_setr_epi32(0x740eef02, 0, 0x9e4addf8, 0);
            y0 = clmul_lo(x0, k), x0 = clmul_hi(x0, k);
            x0 = _mm_ternarylogic_epi64(x0, y0, x4, 0x96);
            x4 = x8;
            y0 = clmul_lo(x0, k), x0 = clmul_hi(x0, k);
            x0 = _mm_ternarylogic_epi64(x0, y0, x4, 0x96);
            /* Final scalar chunk. */
            crc0 = _mm_crc32_u64(crc0, *(const uint64_t *)buf);
            crc1 = _mm_crc32_u64(crc1, *(const uint64_t *)(buf + klen));
            crc2 = _mm_crc32_u64(crc2, *(const uint64_t *)(buf + klen * 2));
            crc3 = _mm_crc32_u64(crc3, *(const uint64_t *)(buf + klen * 3));
            crc4 = _mm_crc32_u64(crc4, *(const uint64_t *)(buf + klen * 4));
            crc5 = _mm_crc32_u64(crc5, *(const uint64_t *)(buf + klen * 5));
            crc6 = _mm_crc32_u64(crc6, *(const uint64_t *)(buf + klen * 6));
            crc7 = _mm_crc32_u64(crc7, *(const uint64_t *)(buf + klen * 7));
            crc8 = _mm_crc32_u64(crc8, *(const uint64_t *)(buf + klen * 8));
            crc9 = _mm_crc32_u64(crc9, *(const uint64_t *)(buf + klen * 9));
            crc10 = _mm_crc32_u64(crc10, *(const uint64_t *)(buf + klen * 10));
            crc11 = _mm_crc32_u64(crc11, *(const uint64_t *)(buf + klen * 11));
            crc12 = _mm_crc32_u64(crc12, *(const uint64_t *)(buf + klen * 12));
            crc13 = _mm_crc32_u64(crc13, *(const uint64_t *)(buf + klen * 13));
            crc14 = _mm_crc32_u64(crc14, *(const uint64_t *)(buf + klen * 14));
            crc15 = _mm_crc32_u64(crc15, *(const uint64_t *)(buf + klen * 15));
            crc0 = _mm_crc32_u64(crc0, *(const uint64_t *)(buf + 8));
            crc1 = _mm_crc32_u64(crc1, *(const uint64_t *)(buf + klen + 8));
            crc2 = _mm_crc32_u64(crc2, *(const uint64_t *)(buf + klen * 2 + 8));
            crc3 = _mm_crc32_u64(crc3, *(const uint64_t *)(buf + klen * 3 + 8));
            crc4 = _mm_crc32_u64(crc4, *(const uint64_t *)(buf + klen * 4 + 8));
            crc5 = _mm_crc32_u64(crc5, *(const uint64_t *)(buf + klen * 5 + 8));
            crc6 = _mm_crc32_u64(crc6, *(const uint64_t *)(buf + klen * 6 + 8));
            crc7 = _mm_crc32_u64(crc7, *(const uint64_t *)(buf + klen * 7 + 8));
            crc8 = _mm_crc32_u64(crc8, *(const uint64_t *)(buf + klen * 8 + 8));
            crc9 = _mm_crc32_u64(crc9, *(const uint64_t *)(buf + klen * 9 + 8));
            crc10 = _mm_crc32_u64(crc10, *(const uint64_t *)(buf + klen * 10 + 8));
            crc11 = _mm_crc32_u64(crc11, *(const uint64_t *)(buf + klen * 11 + 8));
            crc12 = _mm_crc32_u64(crc12, *(const uint64_t *)(buf + klen * 12 + 8));
            crc13 = _mm_crc32_u64(crc13, *(const uint64_t *)(buf + klen * 13 + 8));
            crc14 = _mm_crc32_u64(crc14, *(const uint64_t *)(buf + klen * 14 + 8));
            crc15 = _mm_crc32_u64(crc15, *(const uint64_t *)(buf + klen * 15 + 8));
            crc0 = _mm_crc32_u64(crc0, *(const uint64_t *)(buf + 16));
            crc1 = _mm_crc32_u64(crc1, *(const uint64_t *)(buf + klen + 16));
            crc2 = _mm_crc32_u64(crc2, *(const uint64_t *)(buf + klen * 2 + 16));
            crc3 = _mm_crc32_u64(crc3, *(const uint64_t *)(buf + klen * 3 + 16));
            crc4 = _mm_crc32_u64(crc4, *(const uint64_t *)(buf + klen * 4 + 16));
            crc5 = _mm_crc32_u64(crc5, *(const uint64_t *)(buf + klen * 5 + 16));
            crc6 = _mm_crc32_u64(crc6, *(const uint64_t *)(buf + klen * 6 + 16));
            crc7 = _mm_crc32_u64(crc7, *(const uint64_t *)(buf + klen * 7 + 16));
            crc8 = _mm_crc32_u64(crc8, *(const uint64_t *)(buf + klen * 8 + 16));
            crc9 = _mm_crc32_u64(crc9, *(const uint64_t *)(buf + klen * 9 + 16));
            crc10 = _mm_crc32_u64(crc10, *(const uint64_t *)(buf + klen * 10 + 16));
            crc11 = _mm_crc32_u64(crc11, *(const uint64_t *)(buf + klen * 11 + 16));
            crc12 = _mm_crc32_u64(crc12, *(const uint64_t *)(buf + klen * 12 + 16));
            crc13 = _mm_crc32_u64(crc13, *(const uint64_t *)(buf + klen * 13 + 16));
            crc14 = _mm_crc32_u64(crc14, *(const uint64_t *)(buf + klen * 14 + 16));
            crc15 = _mm_crc32_u64(crc15, *(const uint64_t *)(buf + klen * 15 + 16));
            crc0 = _mm_crc32_u64(crc0, *(const uint64_t *)(buf + 24));
            crc1 = _mm_crc32_u64(crc1, *(const uint64_t *)(buf + klen + 24));
            crc2 = _mm_crc32_u64(crc2, *(const uint64_t *)(buf + klen * 2 + 24));
            crc3 = _mm_crc32_u64(crc3, *(const uint64_t *)(buf + klen * 3 + 24));
            crc4 = _mm_crc32_u64(crc4, *(const uint64_t *)(buf + klen * 4 + 24));
            crc5 = _mm_crc32_u64(crc5, *(const uint64_t *)(buf + klen * 5 + 24));
            crc6 = _mm_crc32_u64(crc6, *(const uint64_t *)(buf + klen * 6 + 24));
            crc7 = _mm_crc32_u64(crc7, *(const uint64_t *)(buf + klen * 7 + 24));
            crc8 = _mm_crc32_u64(crc8, *(const uint64_t *)(buf + klen * 8 + 24));
            crc9 = _mm_crc32_u64(crc9, *(const uint64_t *)(buf + klen * 9 + 24));
            crc10 = _mm_crc32_u64(crc10, *(const uint64_t *)(buf + klen * 10 + 24));
            crc11 = _mm_crc32_u64(crc11, *(const uint64_t *)(buf + klen * 11 + 24));
            crc12 = _mm_crc32_u64(crc12, *(const uint64_t *)(buf + klen * 12 + 24));
            crc13 = _mm_crc32_u64(crc13, *(const uint64_t *)(buf + klen * 13 + 24));
            crc14 = _mm_crc32_u64(crc14, *(const uint64_t *)(buf + klen * 14 + 24));
            crc15 = _mm_crc32_u64(crc15, *(const uint64_t *)(buf + klen * 15 + 24));
            crc0 = _mm_crc32_u64(crc0, *(const uint64_t *)(buf + 32));
            crc1 = _mm_crc32_u64(crc1, *(const uint64_t *)(buf + klen + 32));
            crc2 = _mm_crc32_u64(crc2, *(const uint64_t *)(buf + klen * 2 + 32));
            crc3 = _mm_crc32_u64(crc3, *(const uint64_t *)(buf + klen * 3 + 32));
            crc4 = _mm_crc32_u64(crc4, *(const uint64_t *)(buf + klen * 4 + 32));
            crc5 = _mm_crc32_u64(crc5, *(const uint64_t *)(buf + klen * 5 + 32));
            crc6 = _mm_crc32_u64(crc6, *(const uint64_t *)(buf + klen * 6 + 32));
            crc7 = _mm_crc32_u64(crc7, *(const uint64_t *)(buf + klen * 7 + 32));
            crc8 = _mm_crc32_u64(crc8, *(const uint64_t *)(buf + klen * 8 + 32));
            crc9 = _mm_crc32_u64(crc9, *(const uint64_t *)(buf + klen * 9 + 32));
            crc10 = _mm_crc32_u64(crc10, *(const uint64_t *)(buf + klen * 10 + 32));
            crc11 = _mm_crc32_u64(crc11, *(const uint64_t *)(buf + klen * 11 + 32));
            crc12 = _mm_crc32_u64(crc12, *(const uint64_t *)(buf + klen * 12 + 32));
            crc13 = _mm_crc32_u64(crc13, *(const uint64_t *)(buf + klen * 13 + 32));
            crc14 = _mm_crc32_u64(crc14, *(const uint64_t *)(buf + klen * 14 + 32));
            crc15 = _mm_crc32_u64(crc15, *(const uint64_t *)(buf + klen * 15 + 32));
            vc0 = crc_shift(crc0, klen * 15 + blk * 384);
            vc1 = crc_shift(crc1, klen * 14 + blk * 384);
            vc2 = crc_shift(crc2, klen * 13 + blk * 384);
            vc3 = crc_shift(crc3, klen * 12 + blk * 384);
            vc4 = crc_shift(crc4, klen * 11 + blk * 384);
            vc5 = crc_shift(crc5, klen * 10 + blk * 384);
            vc6 = crc_shift(crc6, klen * 9 + blk * 384);
            vc7 = crc_shift(crc7, klen * 8 + blk * 384);
            vc8 = crc_shift(crc8, klen * 7 + blk * 384);
            vc9 = crc_shift(crc9, klen * 6 + blk * 384);
            vc10 = crc_shift(crc10, klen * 5 + blk * 384);
            vc11 = crc_shift(crc11, klen * 4 + blk * 384);
            vc12 = crc_shift(crc12, klen * 3 + blk * 384);
            vc13 = crc_shift(crc13, klen * 2 + blk * 384);
            vc14 = crc_shift(crc14, klen + blk * 384);
            vc15 = crc_shift(crc15, 0 + blk * 384);
            vc = _mm_extract_epi64(
                _mm_ternarylogic_epi64(
                    _mm_ternarylogic_epi64(vc0, _mm_ternarylogic_epi64(vc1, vc2, vc3, 0x96), vc4, 0x96),
                    _mm_ternarylogic_epi64(_mm_xor_si128(vc5, vc6), _mm_xor_si128(vc7, vc8), _mm_xor_si128(vc9, vc10),
                                           0x96),
                    _mm_ternarylogic_epi64(vc11, _mm_ternarylogic_epi64(vc12, vc13, vc14, 0x96), vc15, 0x96), 0x96),
                0);
            /* Reduce 128 bits to 32 bits, and multiply by x^32. */
            crc0 = _mm_crc32_u64(0, _mm_extract_epi64(x0, 0));
            crc0 = _mm_crc32_u64(crc0, vc ^ _mm_extract_epi64(x0, 1));
            buf = buf2;
            len = end - buf;
        }
        for (; len >= 8; buf += 8, len -= 8)
        {
            crc0 = _mm_crc32_u64(crc0, *(const uint64_t *)buf);
        }
        for (; len; --len)
        {
            crc0 = _mm_crc32_u8(crc0, *buf++);
        }
        return ~crc0;
    }
}